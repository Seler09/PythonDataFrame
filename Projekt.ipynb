{"cells":[{"cell_type":"markdown","source":["#<p style=\"color: black\">_Projekt Big Data_</p>\n<p style=\"color: grey\">Bartosz Kalinka 217120 <br/> Paweł Kolak <br/> Dawid Heller 218489 <br/> Śr 9:15</p>"],"metadata":{}},{"cell_type":"markdown","source":["## Zbiór danych\n<p>\nInformacje o zbiorze danych:\n<ul>\n<li style = \"color: red\">opis (cel analizy),</li>\n  <li>Plik .csv pochodzi ze strony \"http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/\". <br/>\n  Baza składa się dokładnie z 50 000 krotek (wierszy).</li>\n  <li>Plik został zaimporotwany w zakładce \"Data\". Po wygenerowaniu tabeli, zostraje on przypisana do zmiennej \"raw_data\"</li>\n  <li><table>\n      <tr>\n        <th>Name</th>\n        <td>Region</td> \n        <td>Country</td>\n        <td>Item Type</td>\n        <td>Sales Channel</td>\n        <td>Order Priority</td>\n        <td>Order Date</td>\n        <td>Order ID</td>\n        <td>Ship Date</td>\n        <td>Units Sold</td>\n        <td>Unit Price</td>\n        <td>Unit Cost</td>\n        <td>Total Revenue</td>\n        <td>Total Cost</td>\n        <td>Total Profit</td>\n      </tr>\n      <tr>\n        <th>Type</th>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>String</td>\n        <td>Integer</td>\n        <td>Double</td>\n        <td>Double</td>\n        <td>Double</td>\n        <td>Double</td>\n        <td>Double</td>\n      </tr>\n    </table>\n  </li>\n</ul>\n</p>"],"metadata":{}},{"cell_type":"code","source":["local_file_path = '/FileStore/tables/sales_records.csv'\nraw_data_test = sc.textFile(local_file_path)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["## Analiza danych"],"metadata":{}},{"cell_type":"markdown","source":["### _Zadanie 1 (Import danych)_"],"metadata":{}},{"cell_type":"markdown","source":["#### Załadowanie danych do RDD"],"metadata":{}},{"cell_type":"code","source":["local_file_path = '/FileStore/tables/sales_records.csv'\nraw_data = sc.textFile(local_file_path)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["#### Załadowanie danych do DataFrame (moduł Apache Spark SQL)"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\ncsv_data_rdd = raw_data.map(lambda row: row.split(','))\n\ndata_df = spark.createDataFrame(csv_data_rdd,('Region','Country','ItemType','SalesChannel','OrderPriority','OrderDate','OrderID','ShipDate','UnitsSold','UnitPrice','UnitCost','TotalRevenue','TotalCost','TotalProfit'))\n\ndata_df = data_df.withColumn(\"UnitsSold\", data_df['UnitsSold'].cast(IntegerType()))\ndata_df = data_df.withColumn(\"UnitPrice\", data_df['UnitPrice'].cast(DoubleType()))\ndata_df = data_df.withColumn(\"UnitCost\", data_df['UnitCost'].cast(DoubleType()))\ndata_df = data_df.withColumn(\"TotalRevenue\", data_df['TotalRevenue'].cast(DoubleType()))\ndata_df = data_df.withColumn(\"TotalCost\", data_df['TotalCost'].cast(DoubleType()))\ndata_df = data_df.withColumn(\"TotalProfit\", data_df['TotalProfit'].cast(DoubleType()))\n\ndata_df.printSchema()\n# Show rows\ndata_df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Region: string (nullable = true)\n-- Country: string (nullable = true)\n-- ItemType: string (nullable = true)\n-- SalesChannel: string (nullable = true)\n-- OrderPriority: string (nullable = true)\n-- OrderDate: string (nullable = true)\n-- OrderID: string (nullable = true)\n-- ShipDate: string (nullable = true)\n-- UnitsSold: integer (nullable = true)\n-- UnitPrice: double (nullable = true)\n-- UnitCost: double (nullable = true)\n-- TotalRevenue: double (nullable = true)\n-- TotalCost: double (nullable = true)\n-- TotalProfit: double (nullable = true)\n\n+--------------------+-----------+---------------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\n              Region|    Country|       ItemType|SalesChannel|OrderPriority| OrderDate|  OrderID|  ShipDate|UnitsSold|UnitPrice|UnitCost|TotalRevenue| TotalCost|TotalProfit|\n+--------------------+-----------+---------------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\n  Sub-Saharan Africa|    Namibia|      Household|     Offline|            M| 8/31/2015|897751939|10/12/2015|     3604|   668.27|  502.54|  2408445.08|1811154.16|  597290.92|\n              Europe|    Iceland|      Baby Food|      Online|            H|11/20/2010|599480426|  1/9/2011|     8435|   255.28|  159.42|   2153286.8| 1344707.7|   808579.1|\n              Europe|     Russia|           Meat|      Online|            L| 6/22/2017|538911855| 6/25/2017|     4848|   421.89|  364.69|  2045322.72|1768017.12|   277305.6|\n              Europe|   Moldova |           Meat|      Online|            L| 2/28/2012|459845054| 3/20/2012|     7225|   421.89|  364.69|  3048155.25|2634885.25|   413270.0|\n              Europe|      Malta|         Cereal|      Online|            M| 8/12/2010|626391351| 9/13/2010|     1975|    205.7|  117.11|    406257.5| 231292.25|  174965.25|\n                Asia|  Indonesia|           Meat|      Online|            H| 8/20/2010|472974574| 8/27/2010|     2542|   421.89|  364.69|  1072444.38| 927041.98|   145402.4|\n  Sub-Saharan Africa|   Djibouti|      Household|      Online|            M|  2/3/2011|854331052|  3/3/2011|     4398|   668.27|  502.54|  2939051.46|2210170.92|  728880.54|\n              Europe|     Greece|      Household|      Online|            L| 9/11/2015|895509612| 9/26/2015|       49|   668.27|  502.54|    32745.23|  24624.46|    8120.77|\n  Sub-Saharan Africa|   Cameroon|      Cosmetics|     Offline|            M| 1/31/2014|241871583|  2/4/2014|     4031|    437.2|  263.33|   1762353.2|1061483.23|  700869.97|\n  Sub-Saharan Africa|    Nigeria|      Cosmetics|      Online|            C|11/21/2015|409090793| 12/7/2015|     7911|    437.2|  263.33|   3458689.2|2083203.63| 1375485.57|\n  Sub-Saharan Africa|    Senegal|         Fruits|     Offline|            M| 8/29/2016|733153569| 10/5/2016|     5288|     9.33|    6.92|    49337.04|  36592.96|   12744.08|\nMiddle East and N...|Afghanistan|      Cosmetics|     Offline|            L|10/21/2016|620358741| 12/1/2016|     6792|    437.2|  263.33|   2969462.4|1788537.36| 1180925.04|\n                Asia|      India|     Vegetables|      Online|            C| 3/21/2010|897317636|  4/5/2010|     5084|   154.06|   90.93|   783241.04| 462288.12|  320952.92|\nMiddle East and N...|    Lebanon|     Vegetables|      Online|            L|10/15/2010|660954082|11/19/2010|     9855|   154.06|   90.93|   1518261.3| 896115.15|  622146.15|\nMiddle East and N...|     Turkey|Office Supplies|      Online|            L| 10/4/2010|428504407|11/13/2010|     2831|   651.21|  524.96|  1843575.51|1486161.76|  357413.75|\nMiddle East and N...|       Iraq|      Cosmetics|     Offline|            M|10/14/2014|787517440|10/19/2014|     2766|    437.2|  263.33|   1209295.2| 728370.78|  480924.42|\n  Sub-Saharan Africa|     Rwanda|  Personal Care|     Offline|            M| 6/15/2013|145854508|  7/8/2013|      445|    81.73|   56.67|    36369.85|  25218.15|    11151.7|\n              Europe|    Ukraine|      Baby Food|     Offline|            M|  5/7/2017|581689441| 5/29/2017|     3687|   255.28|  159.42|   941217.36| 587781.54|  353435.82|\n              Europe|    Finland|Office Supplies|      Online|            H| 5/21/2015|193508565|  7/3/2015|     2339|   651.21|  524.96|  1523180.19|1227881.44|  295298.75|\n  Sub-Saharan Africa|South Sudan|      Beverages|     Offline|            H| 6/28/2016|750110709| 7/14/2016|     3283|    47.45|   31.79|   155778.35| 104366.57|   51411.78|\n+--------------------+-----------+---------------+------------+-------------+----------+---------+----------+---------+---------+--------+------------+----------+-----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### _Zadanie 2 (Agregacja)_\n<p style=\"color: red\">Sekcja opisująca 2 hipotezy które chcemy zwalidować za pomocą danych.\n\nNa podstawie ramki RDD i DSL DataFrame należy wykonać funkcje agregującą dane (dwie różne, nie trywialne) i opisać uzyskane wyniki.</p>"],"metadata":{}},{"cell_type":"code","source":["# agregacja danych z wykorzystaniem RDD\nprint(csv_data_rdd.count()) #liczba wszystkich rekordów\n\nnormal_raw_data_rdd2 = csv_data_rdd.filter(lambda row: 'Europe' in row)\n\nprint(normal_raw_data_rdd2.count()) #liczba rekrodów, po filtrowaniu (Dane z Europy)\nprint(normal_raw_data_rdd2.take(1)) #pierwsyz rekord, po filtrowaniu\n\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">50000\n12841\n[[&apos;Europe&apos;, &apos;Iceland&apos;, &apos;Baby Food&apos;, &apos;Online&apos;, &apos;H&apos;, &apos;11/20/2010&apos;, &apos;599480426&apos;, &apos;1/9/2011&apos;, &apos;8435&apos;, &apos;255.28&apos;, &apos;159.42&apos;, &apos;2153286.80&apos;, &apos;1344707.70&apos;, &apos;808579.10&apos;]]\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# agregacja danych z wykorzystaniem DSL Apache Spark SQL (DataFrame)\ndf = data_df\ndf_Europe = df.filter(df[\"Region\"] == \"Europe\")\n\ndf_Europe.count()\ndf_Europe.show()\n\ndf.groupBy(\"Order Priority\").count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3930114539581187&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      6</span> df_Europe<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      7</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 8</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>groupBy<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Order Priority&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>count<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/group.py</span> in <span class=\"ansicyan\">_api</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">     30</span>     <span class=\"ansigreen\">def</span> _api<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     31</span>         name <span class=\"ansiyellow\">=</span> f<span class=\"ansiyellow\">.</span>__name__<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 32</span><span class=\"ansiyellow\">         </span>jdf <span class=\"ansiyellow\">=</span> getattr<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jgd<span class=\"ansiyellow\">,</span> name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     33</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     34</span>     _api<span class=\"ansiyellow\">.</span>__name__ <span class=\"ansiyellow\">=</span> f<span class=\"ansiyellow\">.</span>__name__<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &quot;cannot resolve &apos;&#96;Order Priority&#96;&apos; given input columns: [UnitPrice, UnitCost, TotalCost, Region, OrderPriority, ItemType, TotalRevenue, Country, OrderDate, SalesChannel, ShipDate, TotalProfit, UnitsSold, OrderID];;\\n&apos;Aggregate [&apos;Order Priority], [&apos;Order Priority, count(1) AS count#1734L]\\n+- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1524, UnitPrice#1539, UnitCost#1554, TotalRevenue#1569, TotalCost#1584, cast(TotalProfit#1509 as double) AS TotalProfit#1599]\\n   +- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1524, UnitPrice#1539, UnitCost#1554, TotalRevenue#1569, cast(TotalCost#1508 as double) AS TotalCost#1584, TotalProfit#1509]\\n      +- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1524, UnitPrice#1539, UnitCost#1554, cast(TotalRevenue#1507 as double) AS TotalRevenue#1569, TotalCost#1508, TotalProfit#1509]\\n         +- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1524, UnitPrice#1539, cast(UnitCost#1506 as double) AS UnitCost#1554, TotalRevenue#1507, TotalCost#1508, TotalProfit#1509]\\n            +- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1524, cast(UnitPrice#1505 as double) AS UnitPrice#1539, UnitCost#1506, TotalRevenue#1507, TotalCost#1508, TotalProfit#1509]\\n               +- Project [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, cast(UnitsSold#1504 as int) AS UnitsSold#1524, UnitPrice#1505, UnitCost#1506, TotalRevenue#1507, TotalCost#1508, TotalProfit#1509]\\n                  +- LogicalRDD [Region#1496, Country#1497, ItemType#1498, SalesChannel#1499, OrderPriority#1500, OrderDate#1501, OrderID#1502, ShipDate#1503, UnitsSold#1504, UnitPrice#1505, UnitCost#1506, TotalRevenue#1507, TotalCost#1508, TotalProfit#1509], false\\n&quot;</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["_<p style=\"color: red\">Opis wyników uzyskanych w obu przypadkach</p>_"],"metadata":{}},{"cell_type":"markdown","source":["### _Zadanie 3 (SQL)_\n<p style=\"color: red\">Sekcja opisująca hipotezę którą chcemy zwalidować za pomocą danych (podobnie jak punkt wyżej). Obiekt DataFrame należy zapisać jako tabela w pamięci, wykonać zapytanie SQL w komórce i **zwizualizować wynik**.</p>"],"metadata":{}},{"cell_type":"code","source":["# kod tutaj\n# ..."],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["_<p style=\"color: red\">Opis uzyskanych wyników</p>_"],"metadata":{}},{"cell_type":"markdown","source":["### _Zadanie 4 (UDF)_\n<p style=\"color: red\">Sekcja opisująca hipotezę którą chcemy zwalidować za pomocą danych. Należy utworzyć i wywołać własną funkcję UDF odpowiednio transformującą daną kolumnę, zaprezentować i opisać rezultat.</p>"],"metadata":{}},{"cell_type":"code","source":["# kod tutaj\n# ..."],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["_<p style=\"color: red\">Opis uzyskanych wyników</p>_"],"metadata":{}},{"cell_type":"markdown","source":["### _Zadanie 5 (MLlib)_\n<p style=\"color: red\">Należy wywołać dowolny algorytm (klasyfikacja, regresja, rekomendacja) z pakietu MLlib w celu przeprowadzenia analizy predyktywnej na istniejących danych.</p>"],"metadata":{}},{"cell_type":"code","source":["# podział na zbiory testowe/treningowe\n# deklaracja alogrytmu\n# zadeklarowana siatka parametrów dla testowania krzyżowego\n# obliczenie metryk dla zbioru testowego\n\n# kod tutaj\n# ..."],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["_<p style=\"color: red\">Opis uzyskanych wyników</p>_"],"metadata":{}},{"cell_type":"markdown","source":["## Podsumowanie\n_<p style=\"color: red\">Krótki wnioski z przeprowadzonej analizy.</p>_\n\n### Dystrybucja notatnika\n1. Wyeksportować notatnik do formatu `IPython Notebook`\n2. Utworzyć archiwum ZIP zawierająca ww. notatnik i plik z użytymi danymi\n3. Archiwum powinno być zawierać numery indeksów autorów projektu (np. `XXX_YYY.zip`)\n4. Archiwum należy wysłać pod adres `norbert.kozlowski@pwr.edu.pl`."],"metadata":{}}],"metadata":{"name":"project_template","notebookId":3930114539581175},"nbformat":4,"nbformat_minor":0}
